# Gandalf — Notes de jailbreak

## 1. Contexte
- Niveau atteint : …
- Temps passé / nombre de tentatives : …
- Version du jeu (URL, mode choisi) : …

## 2. Tactiques d’attaque testées
- Reformulation de la question interdite : …
- Jeu de rôle (roleplay) : …
- Traduction / changement de langue : …
- Séparation de la question en étapes : …
- Autres (prompt injection, demande de résumé d’une réponse interdite, etc.) : …

## 3. Réponses du modèle
- Cas où la défense tient bien : …
- Cas où la défense échoue (jailbreak réussi) : …
- Types d’informations révélées dans les échecs : …

## 4. Mapping aux risques (OWASP LLM Top-10 / MITRE ATLAS)
- OWASP LLM Top-10 concernés (par ex. LLM01 Prompt Injection, LLM02 Data Leakage, etc.) : …
- Techniques MITRE ATLAS pertinentes (exemples) : …

## 5. Leçons apprises
- Patterns de prompts “dangereux” repérés : …
- Idées d’amélioration des défenses (filtrage, règles, etc.) : …
